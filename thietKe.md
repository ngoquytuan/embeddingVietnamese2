# T√ÄI LI·ªÜU H∆Ø·ªöNG D·∫™N TRI·ªÇN KHAI
## FR-01.1: ƒê√ÅNH GI√Å V√Ä L·ª∞A CH·ªåN EMBEDDING MODELS TI·∫æNG VI·ªÜT

---

**Phi√™n b·∫£n:** 1.0  
**Ng√†y:** 30/08/2025  
**M·ª•c ti√™u:** X√¢y d·ª±ng h·ªá th·ªëng ƒë√°nh gi√° v√† l·ª±a ch·ªçn embedding models t·ªëi ∆∞u cho ti·∫øng Vi·ªát  
**Th·ªùi gian ∆∞·ªõc t√≠nh:** 1-2 tu·∫ßn  

---

## üìã **T·ªîNG QUAN D·ª∞ √ÅN**

### **M·ª•c ti√™u ch√≠nh:**
- ƒê√°nh gi√° v√† so s√°nh t·ªëi thi·ªÉu 5 embedding models cho ti·∫øng Vi·ªát
- ƒêo l∆∞·ªùng hi·ªáu su·∫•t v·ªõi metrics: Hit Rate v√† Mean Reciprocal Rank (MRR)
- L·ª±a ch·ªçn 2-3 models t·ªët nh·∫•t ƒë·ªÉ s·ª≠ d·ª•ng trong production
- T·ªëi ∆∞u h√≥a cho GPU v√† d·ªØ li·ªáu ti·∫øng Vi·ªát

### **Deliverables:**
- Framework ƒë√°nh gi√° embedding models
- B√°o c√°o so s√°nh chi ti·∫øt v·ªõi metrics
- Top 2-3 models ƒë∆∞·ª£c khuy·∫øn ngh·ªã
- H∆∞·ªõng d·∫´n tri·ªÉn khai production

---

## üèóÔ∏è **C·∫§U TR√öC D·ª∞ √ÅN**

```
vietnamese_embedding_evaluator/
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ models.json              # C·∫•u h√¨nh c√°c models c·∫ßn test
‚îÇ   ‚îú‚îÄ‚îÄ evaluation_settings.json # Tham s·ªë ƒë√°nh gi√°
‚îÇ   ‚îî‚îÄ‚îÄ gpu_settings.json        # C·∫•u h√¨nh GPU
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ company_documents/   # T√†i li·ªáu n·ªôi b·ªô m·∫´u
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ external_datasets/   # Dataset c√¥ng khai (n·∫øu c√≥)
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cleaned_corpus.json  # D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_queries.json    # B·ªô c√¢u h·ªèi test
‚îÇ   ‚îî‚îÄ‚îÄ ground_truth/
‚îÇ       ‚îî‚îÄ‚îÄ query_document_pairs.json # C·∫∑p c√¢u h·ªèi-t√†i li·ªáu ƒë√∫ng
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py        # X·ª≠ l√Ω d·ªØ li·ªáu ti·∫øng Vi·ªát
‚îÇ   ‚îú‚îÄ‚îÄ embedding_manager.py     # Qu·∫£n l√Ω c√°c embedding models
‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py            # Logic ƒë√°nh gi√° metrics
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py              # T√≠nh to√°n Hit Rate, MRR
‚îÇ   ‚îú‚îÄ‚îÄ gpu_optimizer.py        # T·ªëi ∆∞u GPU
‚îÇ   ‚îî‚îÄ‚îÄ visualizer.py           # T·∫°o charts v√† reports
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_model_comparison.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_results_analysis.ipynb
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison_report.json
‚îÇ   ‚îú‚îÄ‚îÄ performance_charts/
‚îÇ   ‚îî‚îÄ‚îÄ final_recommendation.md
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ run_evaluation.py       # Script ch√≠nh
‚îÇ   ‚îú‚îÄ‚îÄ prepare_data.py         # Chu·∫©n b·ªã d·ªØ li·ªáu
‚îÇ   ‚îî‚îÄ‚îÄ export_results.py       # Xu·∫•t k·∫øt qu·∫£
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_embedding_models.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ setup.py
‚îî‚îÄ‚îÄ README.md
```

---

## üîß **C√îNG NGH·ªÜ V√Ä TH√ÄNH PH·∫¶N**

### **1. Core Libraries & Frameworks:**
```txt
# Embedding & ML Libraries
sentence-transformers>=2.2.2
transformers>=4.21.0
torch>=2.0.0
numpy>=1.21.0
scikit-learn>=1.1.0

# Vietnamese Text Processing
pyvi>=0.1.1                    # Tokenizer ti·∫øng Vi·ªát
regex>=2022.7.9                # Advanced regex patterns
unicodedata2>=15.0.0           # Unicode normalization

# GPU Optimization
accelerate>=0.20.0             # HuggingFace GPU acceleration
cuda-python>=12.0.0            # CUDA utilities (n·∫øu c√≥)

# Data Processing & Analysis
pandas>=1.5.0
numpy>=1.21.0
scipy>=1.9.0

# Visualization & Reporting
matplotlib>=3.5.0
seaborn>=0.11.0
plotly>=5.10.0
jinja2>=3.1.0                  # Template engine cho reports

# Utilities
tqdm>=4.64.0                   # Progress bars
python-dotenv>=0.19.0          # Environment variables
pydantic>=1.10.0               # Data validation
typer>=0.6.0                   # CLI interface
```

### **2. Embedding Models ƒë∆∞·ª£c ƒë√°nh gi√°:**

#### **Top Priority Models:**
1. **AITeamVN/Vietnamese_Embedding** (Recommended #1)
   - Hugging Face Model ID: `AITeamVN/Vietnamese_Embedding`
   - ƒê·∫∑c bi·ªát t·ªëi ∆∞u cho ti·∫øng Vi·ªát
   - Size: ~400MB

2. **Qwen/Qwen3-Embedding-0.6B** (Recommended #2)
   - Hugging Face Model ID: `Qwen/Qwen2.5-72B-Instruct`
   - Multilingual support t·ªët
   - Size: ~600MB

#### **Additional Models for Comparison:**
3. **sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2**
   - Multilingual, compact
   - Size: ~200MB

4. **intfloat/multilingual-e5-base**
   - E5 series, multilingual
   - Size: ~400MB

5. **BAAI/bge-m3**
   - Chinese-focus nh∆∞ng support Vietnamese
   - Size: ~600MB

6. **keepitreal/vietnamese-sbert** (Backup option)
   - Vietnamese-specific SBERT
   - Size: ~400MB

---

## üìù **STEP-BY-STEP IMPLEMENTATION GUIDE**

### **Phase 1: Setup & Data Preparation (2-3 ng√†y)**

#### **Step 1.1: Environment Setup**
```bash
# T·∫°o Python virtual environment
python -m venv venv_embedding_eval
source venv_embedding_eval/bin/activate  # Linux/Mac
# ho·∫∑c venv_embedding_eval\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Ki·ªÉm tra GPU availability
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

#### **Step 1.2: Data Collection & Preprocessing**

**1.2.1 Thu th·∫≠p d·ªØ li·ªáu c√¥ng ty:**
- L·∫•y 200-500 t√†i li·ªáu n·ªôi b·ªô ƒë·∫°i di·ªán (PDF, Word, txt)
- ƒê·∫£m b·∫£o c√≥ ƒëa d·∫°ng lo·∫°i: quy tr√¨nh, h∆∞·ªõng d·∫´n k·ªπ thu·∫≠t, ch√≠nh s√°ch
- Ph√¢n lo·∫°i theo department v√† access level

**1.2.2 T·∫°o Ground Truth Dataset:**
```python
# C·∫•u tr√∫c file data/ground_truth/query_document_pairs.json
{
  "test_cases": [
    {
      "query_id": "Q001",
      "query": "Quy tr√¨nh mua h√†ng tr√¨nh gi√°m ƒë·ªëc nh∆∞ th·∫ø n√†o?",
      "relevant_documents": ["DOC_001", "DOC_003"],
      "department": "procurement",
      "difficulty": "easy"
    },
    {
      "query_id": "Q002", 
      "query": "C√°c t√≠nh nƒÉng c·ªßa ƒë√®n hi·ªáu s√¢n bay lo·∫°i LED?",
      "relevant_documents": ["DOC_045", "DOC_067", "DOC_089"],
      "department": "technical",
      "difficulty": "medium"
    }
  ]
}
```

**1.2.3 Text Processing Pipeline:**
```python
# H∆∞·ªõng d·∫´n implement trong src/data_processor.py

class VietnameseTextProcessor:
    def __init__(self):
        # S·ª≠ d·ª•ng PyVi tokenizer thay v√¨ underthesea
        pass
    
    def clean_text(self, text: str) -> str:
        # Normalize Unicode
        # Remove special characters
        # Handle Vietnamese diacritics
        # Tokenization v·ªõi PyVi
        pass
    
    def create_chunks(self, document: str, chunk_size: int = 512) -> List[str]:
        # Intelligent chunking cho ti·∫øng Vi·ªát
        # Respect sentence boundaries
        # Handle Vietnamese punctuation
        pass
```

### **Phase 2: Embedding Models Integration (3-4 ng√†y)**

#### **Step 2.1: Model Manager Implementation**

**2.1.1 C·∫•u h√¨nh models (configs/models.json):**
```json
{
  "models": [
    {
      "name": "vietnamese_embedding_v1",
      "model_id": "AITeamVN/Vietnamese_Embedding",
      "provider": "huggingface",
      "max_seq_length": 512,
      "batch_size": 32,
      "normalize_embeddings": true,
      "priority": 1
    },
    {
      "name": "qwen3_embedding",
      "model_id": "Qwen/Qwen2.5-72B-Instruct", 
      "provider": "huggingface",
      "max_seq_length": 512,
      "batch_size": 16,
      "normalize_embeddings": true,
      "priority": 2
    }
  ],
  "evaluation_settings": {
    "top_k": [1, 3, 5, 10],
    "similarity_threshold": 0.7,
    "batch_processing": true
  }
}
```

**2.1.2 GPU Optimization Strategy:**
```python
# src/gpu_optimizer.py implementation guidance

class GPUOptimizer:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
    def optimize_model_loading(self, model_name: str):
        # Load model v·ªõi GPU optimization
        # Memory management
        # Batch size tuning d·ª±a tr√™n GPU memory
        # Mixed precision n·∫øu GPU h·ªó tr·ª£
        pass
    
    def monitor_gpu_usage(self):
        # Track GPU memory usage
        # Performance metrics
        # Temperature monitoring
        pass
```

#### **Step 2.2: Embedding Generation Pipeline**

**2.2.1 Batch Processing Strategy:**
```python
# src/embedding_manager.py guidance

class EmbeddingManager:
    def __init__(self, gpu_optimizer: GPUOptimizer):
        self.gpu_optimizer = gpu_optimizer
        self.models = {}
    
    def generate_embeddings_batch(self, texts: List[str], model_name: str) -> np.ndarray:
        # Efficient batch processing
        # GPU memory management  
        # Error handling and retry logic
        # Progress tracking
        pass
    
    def compare_models_parallel(self, test_queries: List[str]) -> Dict:
        # Parallel model comparison
        # Resource allocation
        # Result aggregation
        pass
```

### **Phase 3: Evaluation Metrics Implementation (2-3 ng√†y)**

#### **Step 3.1: Core Metrics**

**3.1.1 Hit Rate Implementation:**
```python
# src/metrics.py guidance

def calculate_hit_rate(query_results: List[List[str]], 
                      ground_truth: List[List[str]], 
                      k: int = 5) -> float:
    """
    T√≠nh Hit Rate@K
    
    Args:
        query_results: List of top-K document IDs cho m·ªói query
        ground_truth: List of relevant document IDs cho m·ªói query
        k: Number of top results to consider
        
    Returns:
        Hit rate score (0.0 to 1.0)
    """
    # Implementation logic here
    pass

def calculate_mrr(query_results: List[List[str]], 
                  ground_truth: List[List[str]]) -> float:
    """
    T√≠nh Mean Reciprocal Rank (MRR)
    
    MRR = (1/|Q|) * Œ£(1/rank_i)
    Trong ƒë√≥ rank_i l√† v·ªã tr√≠ c·ªßa relevant document ƒë·∫ßu ti√™n
    """
    # Implementation logic here
    pass
```

**3.1.2 Advanced Metrics:**
```python
def calculate_ndcg(query_results: List[List[str]], 
                   ground_truth: List[List[str]], 
                   k: int = 10) -> float:
    """Normalized Discounted Cumulative Gain"""
    pass

def calculate_precision_recall(query_results: List[List[str]], 
                              ground_truth: List[List[str]]) -> Tuple[float, float]:
    """Precision and Recall at different cut-offs"""
    pass
```

#### **Step 3.2: Evaluation Framework**

**3.2.1 Comprehensive Evaluation:**
```python
# src/evaluator.py guidance

class ModelEvaluator:
    def __init__(self, embedding_manager: EmbeddingManager):
        self.embedding_manager = embedding_manager
        
    def run_full_evaluation(self, test_queries: List[Dict], 
                           document_corpus: List[Dict]) -> Dict:
        """
        Ch·∫°y ƒë√°nh gi√° ƒë·∫ßy ƒë·ªß cho t·∫•t c·∫£ models
        
        Steps:
        1. Generate embeddings cho document corpus
        2. Process test queries
        3. Perform similarity search
        4. Calculate metrics
        5. Generate comparative report
        """
        pass
    
    def benchmark_performance(self, model_name: str) -> Dict:
        """
        Benchmark speed v√† memory usage
        
        Metrics:
        - Embedding generation speed (tokens/second)
        - Memory usage (peak v√† average)
        - GPU utilization
        - Search latency
        """
        pass
```

### **Phase 4: Results Analysis & Visualization (2-3 ng√†y)**

#### **Step 4.1: Report Generation**

**4.1.1 Automated Report Structure:**
```python
# src/visualizer.py guidance

class ReportGenerator:
    def generate_comparison_charts(self, results: Dict) -> None:
        """
        T·∫°o bi·ªÉu ƒë·ªì so s√°nh:
        1. Hit Rate@K comparison (bar chart)
        2. MRR comparison (horizontal bar)
        3. Speed vs Accuracy scatter plot
        4. Memory usage comparison
        5. Per-category performance heatmap
        """
        pass
    
    def create_model_ranking_table(self, results: Dict) -> pd.DataFrame:
        """
        B·∫£ng x·∫øp h·∫°ng models v·ªõi weighted scoring:
        - Accuracy (40%): Average of Hit Rate@5 and MRR
        - Speed (30%): Embedding generation + search speed
        - Memory (20%): GPU memory efficiency
        - Vietnamese-specific (10%): Performance on Vietnamese queries
        """
        pass
    
    def export_final_report(self, results: Dict) -> None:
        """
        T·∫°o b√°o c√°o cu·ªëi c√πng format Markdown + HTML
        Bao g·ªìm:
        - Executive Summary
        - Detailed Results
        - Recommendations
        - Implementation Guide
        """
        pass
```

#### **Step 4.2: Decision Framework**

**4.2.1 Model Selection Criteria:**
```python
# Weighted scoring system
EVALUATION_WEIGHTS = {
    'hit_rate_5': 0.20,      # Hit Rate@5
    'mrr': 0.20,             # Mean Reciprocal Rank
    'embedding_speed': 0.15,  # Tokens per second
    'search_speed': 0.15,     # Query response time
    'memory_efficiency': 0.10, # GPU memory usage
    'vietnamese_performance': 0.10, # Vietnamese-specific test
    'model_size': 0.05,       # Storage requirements
    'stability': 0.05         # Error rate & consistency
}

def calculate_final_score(model_results: Dict) -> float:
    """Calculate weighted final score for model ranking"""
    pass
```

---

## üöÄ **EXECUTION SCRIPTS**

### **Main Evaluation Script (scripts/run_evaluation.py):**
```python
#!/usr/bin/env python3
"""
Main evaluation runner script
Usage: python scripts/run_evaluation.py --config configs/models.json --output reports/
"""

import typer
from pathlib import Path
from src.data_processor import VietnameseTextProcessor
from src.embedding_manager import EmbeddingManager
from src.evaluator import ModelEvaluator
from src.visualizer import ReportGenerator

def main(
    config_path: Path = typer.Option(..., help="Path to models config"),
    data_path: Path = typer.Option("data/", help="Path to data directory"),
    output_path: Path = typer.Option("reports/", help="Output directory"),
    gpu_enabled: bool = typer.Option(True, help="Enable GPU acceleration"),
    verbose: bool = typer.Option(False, help="Verbose logging")
):
    """
    Run complete embedding model evaluation pipeline
    
    Steps executed:
    1. Load and validate configuration
    2. Prepare test data
    3. Initialize models
    4. Run evaluation
    5. Generate reports
    """
    
    # Implementation logic here
    # Load configs, run evaluation, save results
    pass

if __name__ == "__main__":
    typer.run(main)
```

---

## üìä **EXPECTED RESULTS & BENCHMARKS**

### **Performance Targets:**
- **Hit Rate@5**: T·ªëi thi·ªÉu 75% cho Vietnamese queries
- **MRR**: T·ªëi thi·ªÉu 0.65
- **Speed**: < 100ms per query (including embedding + search)
- **Memory**: < 2GB GPU RAM per model

### **Evaluation Categories:**
1. **General Knowledge**: C√¢u h·ªèi chung v·ªÅ company
2. **Technical Documents**: H∆∞·ªõng d·∫´n k·ªπ thu·∫≠t, specifications
3. **Process & Policy**: Quy tr√¨nh, ch√≠nh s√°ch n·ªôi b·ªô
4. **Product Information**: Th√¥ng tin s·∫£n ph·∫©m, features
5. **Cross-Department**: Queries spanning multiple departments

### **Expected Model Ranking (D·ª± ki·∫øn):**
1. **AITeamVN/Vietnamese_Embedding**: Highest Vietnamese performance
2. **Qwen/Qwen3-Embedding-0.6B**: Best balanced performance
3. **intfloat/multilingual-e5-base**: Good multilingual support

---

## üîç **QUALITY ASSURANCE & VALIDATION**

### **Testing Strategy:**
1. **Unit Tests**: Test individual components
2. **Integration Tests**: End-to-end pipeline testing
3. **Performance Tests**: Benchmark under load
4. **Validation Tests**: Cross-validation with holdout dataset

### **Success Criteria:**
- [ ] All 5+ models successfully evaluated
- [ ] Metrics calculated correctly and consistently
- [ ] GPU optimization achieving >70% utilization
- [ ] Reports generated automatically
- [ ] Top 2-3 models clearly identified
- [ ] Production deployment guide ready

---

## üìñ **DOCUMENTATION DELIVERABLES**

### **1. Technical Documentation:**
- API documentation cho embedding manager
- Performance benchmarking results
- GPU optimization guide
- Troubleshooting guide

### **2. Business Reports:**
- Executive summary v·ªõi recommendations
- Detailed comparison report
- Cost-benefit analysis cho production deployment
- Risk assessment v√† mitigation strategies

### **3. Implementation Guides:**
- Production deployment checklist
- Model switching procedures
- Monitoring v√† maintenance procedures
- Scaling guidelines

---

## ‚ö†Ô∏è **KNOWN CHALLENGES & MITIGATION**

### **Technical Challenges:**
1. **GPU Memory Limitations**
   - **Mitigation**: Batch size optimization, model sharding
   
2. **Vietnamese Text Processing Complexity**
   - **Mitigation**: Robust preprocessing pipeline, multiple tokenization strategies
   
3. **Model Loading Time**
   - **Mitigation**: Model caching, lazy loading strategies

4. **Inconsistent Results Across Runs**
   - **Mitigation**: Random seed control, multiple evaluation runs

### **Business Challenges:**
1. **Limited Vietnamese Training Data**
   - **Mitigation**: Data augmentation, synthetic data generation
   
2. **Domain-Specific Performance**
   - **Mitigation**: Fine-tuning experiments, domain adaptation

---

## üéØ **SUCCESS METRICS**

### **Technical Success:**
- Successfully evaluate 5+ embedding models
- Generate reliable Hit Rate v√† MRR metrics
- Achieve production-ready performance benchmarks
- Deliver automated evaluation framework

### **Business Success:**
- Clear recommendation cho top 2-3 models
- Confidence level >80% trong model selection
- Detailed implementation roadmap
- Risk mitigation strategies documented

---

**üìû CONTACT & SUPPORT**
- **Technical Lead**: [T√™n Technical Lead]
- **Project Manager**: [T√™n PM]
- **Documentation**: README.md trong project repository

**T√†i li·ªáu n√†y cung c·∫•p roadmap ƒë·∫ßy ƒë·ªß ƒë·ªÉ implement FR-01.1 m√† kh√¥ng c·∫ßn code c·ª• th·ªÉ. Team k·ªπ thu·∫≠t c√≥ th·ªÉ follow step-by-step guide n√†y ƒë·ªÉ build evaluation framework v√† ch·ªçn embedding models t·ªëi ∆∞u cho h·ªá th·ªëng.**
